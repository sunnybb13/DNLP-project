{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9q2abrB_h6C"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets scikit-learn accelerate\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    set_seed\n",
        ")\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(\"unswnlporg/BESSTIE\")\n",
        "ds"
      ],
      "metadata": {
        "id": "e8wAMFO1_qcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_hf(dataset, task, variety=None, source=None):\n",
        "    def fn(ex):\n",
        "        if ex[\"task\"] != task:\n",
        "            return False\n",
        "        if variety is not None and ex[\"variety\"] != variety:\n",
        "            return False\n",
        "        if source is not None and ex[\"source\"] != source:\n",
        "            return False\n",
        "        return True\n",
        "    return dataset.filter(fn)\n",
        "\n",
        "def has_both_labels(dataset):\n",
        "    labels = set(dataset[\"label\"])\n",
        "    return (0 in labels) and (1 in labels)\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "\n",
        "    acc = accuracy_score(labels, preds)\n",
        "\n",
        "    # importante: forziamo entrambe le label (0 e 1) e gestiamo divisione per zero\n",
        "    f1 = f1_score(labels, preds, average=\"macro\", labels=[0,1], zero_division=0)\n",
        "\n",
        "    return {\"accuracy\": acc, \"f1_macro\": f1}\n"
      ],
      "metadata": {
        "id": "aoZFKMvSBLmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(\n",
        "    ds,\n",
        "    task,\n",
        "    train_variety=None,\n",
        "    train_source=None,\n",
        "    test_variety=None,\n",
        "    test_source=None,\n",
        "    model_name=\"roberta-large\",\n",
        "    seed=7,\n",
        "    max_length=128,\n",
        "    train_epochs=3,\n",
        "    lr=2e-5,\n",
        "    train_bs=16,\n",
        "    eval_bs=32,\n",
        "    fp16=True,\n",
        "    output_dir_prefix=\"EXT\"\n",
        "):\n",
        "    set_seed(seed)\n",
        "\n",
        "    # 1) Filtra train e \"test\" (usiamo validation come test)\n",
        "    train_full = filter_hf(ds[\"train\"], task=task, variety=train_variety, source=train_source)\n",
        "    test_set   = filter_hf(ds[\"validation\"], task=task, variety=test_variety, source=test_source)\n",
        "\n",
        "    # 2) Controlli minimi\n",
        "    if len(train_full) < 50:\n",
        "        return None, f\"SKIP: train troppo piccolo ({len(train_full)})\"\n",
        "    if len(test_set) < 30:\n",
        "        return None, f\"SKIP: test troppo piccolo ({len(test_set)})\"\n",
        "\n",
        "    if not has_both_labels(train_full):\n",
        "        return None, \"SKIP: train ha una sola classe\"\n",
        "\n",
        "    warn_msg = None\n",
        "    if not has_both_labels(test_set):\n",
        "        warn_msg = \"WARN: test ha una sola classe (F1 macro può essere poco informativa)\"\n",
        "\n",
        "    # 3) Split interno train/val (sklearn stratified)\n",
        "    idx = np.arange(len(train_full))\n",
        "    y = np.array(train_full[\"label\"])\n",
        "\n",
        "    # se y ha una sola classe, stratify fallisce (ma l'abbiamo già controllato)\n",
        "    train_idx, val_idx = train_test_split(\n",
        "        idx,\n",
        "        test_size=0.1,\n",
        "        random_state=seed,\n",
        "        stratify=y\n",
        "    )\n",
        "\n",
        "    train_set = train_full.select(train_idx.tolist())\n",
        "    val_set   = train_full.select(val_idx.tolist())\n",
        "\n",
        "    # 4) Tokenizer + preprocess\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    def preprocess_function(batch):\n",
        "        return tokenizer(\n",
        "            batch[\"text\"],\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            padding=\"max_length\"\n",
        "        )\n",
        "\n",
        "    train_set = train_set.map(preprocess_function, batched=True)\n",
        "    val_set   = val_set.map(preprocess_function, batched=True)\n",
        "    test_set  = test_set.map(preprocess_function, batched=True)\n",
        "\n",
        "    cols = [\"input_ids\", \"attention_mask\", \"label\"]\n",
        "    train_set.set_format(\"torch\", columns=cols)\n",
        "    val_set.set_format(\"torch\", columns=cols)\n",
        "    test_set.set_format(\"torch\", columns=cols)\n",
        "\n",
        "    # 5) Model\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=2\n",
        "    )\n",
        "\n",
        "    # 6) TrainingArguments\n",
        "    outdir = (\n",
        "        f\"{output_dir_prefix}_{task}_\"\n",
        "        f\"TR-{train_variety or 'ALL'}-{train_source or 'ALL'}_\"\n",
        "        f\"TE-{test_variety or 'ALL'}-{test_source or 'ALL'}\"\n",
        "    )\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=outdir,\n",
        "        num_train_epochs=train_epochs,\n",
        "        learning_rate=lr,\n",
        "        per_device_train_batch_size=train_bs,\n",
        "        per_device_eval_batch_size=eval_bs,\n",
        "        weight_decay=0.01,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1_macro\",\n",
        "        logging_steps=100,\n",
        "        fp16=fp16,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    # 7) Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_set,\n",
        "        eval_dataset=val_set,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    # 8) Evaluate sul \"test\" (validation HF filtrata)\n",
        "    test_metrics = trainer.evaluate(test_set)\n",
        "\n",
        "    result = {\n",
        "        \"task\": task,\n",
        "        \"train_variety\": train_variety,\n",
        "        \"train_source\": train_source,\n",
        "        \"test_variety\": test_variety,\n",
        "        \"test_source\": test_source,\n",
        "        \"n_train\": len(train_full),\n",
        "        \"n_test\": len(test_set),\n",
        "        \"test_accuracy\": test_metrics.get(\"eval_accuracy\"),\n",
        "        \"test_f1_macro\": test_metrics.get(\"eval_f1_macro\"),\n",
        "        \"note\": warn_msg\n",
        "    }\n",
        "    return result, None\n"
      ],
      "metadata": {
        "id": "Y1ZxS1B1BspA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "VARIETIES = [\"en-AU\", \"en-IN\", \"en-UK\"]\n",
        "\n",
        "results = []\n",
        "errors = []\n",
        "\n",
        "TASK = \"Sarcasm\"\n",
        "SOURCE_FIXED = \"Reddit\"\n",
        "\n",
        "# ESEMPIO: fai solo una riga (train en-AU -> test en-IN/en-UK) per non farlo pesantissimo\n",
        "TRAIN_VAR = \"en-AU\"\n",
        "for test_var in VARIETIES:\n",
        "    res, err = run_experiment(\n",
        "        ds,\n",
        "        task=TASK,\n",
        "        train_variety=TRAIN_VAR,\n",
        "        train_source=SOURCE_FIXED,\n",
        "        test_variety=test_var,\n",
        "        test_source=SOURCE_FIXED,\n",
        "        model_name=\"roberta-large\",\n",
        "        output_dir_prefix=\"CROSSVAR\"\n",
        "    )\n",
        "    if res is not None:\n",
        "        results.append(res)\n",
        "    else:\n",
        "        errors.append({\"setting\": f\"{TRAIN_VAR}->{test_var}\", \"error\": err})\n",
        "\n",
        "pd.DataFrame(results)\n"
      ],
      "metadata": {
        "id": "81v6VxeZBvDm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}